# ğŸ§  personalâ€‘kg

> **darkhanakhâ€™s selfâ€‘hosted personal AI stack** â€” builds and maintains your own knowledge graph, vector memory, and agentic layer to understand, recall, and act on everything about you.

---

## ğŸš€ Overview

**personalâ€‘kg** is a TypeScriptâ€‘native, localâ€‘first AI monorepo.  
It ingests your notes into a **graphâ€¯+â€¯vector memory**, powers them with **LLMs**, and exposes an **APIâ€¯+â€¯UI** for querying and reflection.

This repo runs entirely on your machine for privacy and efficiency.  
The stack includes:

- **apps/web** â†’Â Next.js frontend (chatâ€¯+â€¯dashboard)  
- **apps/server** â†’Â NestJS backend (APIâ€¯+â€¯retrieval)  
- **packages/knowledge** â†’Â NodeRAG ingestionâ€¯+â€¯graph logic  
- **packages/configs** â†’Â ESLintâ€¯/â€¯TSâ€¯config shared by all packages  

---

## ğŸ§© Architecture

```mermaid
graph LR
    A[notes/<br/>Human layer] --> B[packages/knowledge<br/>Parser + Indexer]
    B --> C[(Neo4j + Qdrant<br/>Memory layer)]
    B --> D[apps/server<br/>API & Agents]
    D --> E[apps/web<br/>Chat / UI]
    
    style A fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    style B fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    style C fill:#fff3e0,stroke:#e65100,stroke-width:2px
    style D fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    style E fill:#fce4ec,stroke:#880e4f,stroke-width:2px
```

- **Graph DB:** Neo4j (entities, relationships)
- **Vector DB:** Qdrant (semantic memory)
- **LLM runtime:** Local (Ollama)â€¯orâ€¯remoteâ€¯(GPTâ€‘5)
- **Monorepo toolchain:** Turborepoâ€¯+â€¯pnpmâ€¯+â€¯TypeScript

---

## âš™ï¸ Setup

### 1.â€¯Clone & Install
```bash
git clone https://github.com/darkhanakh/personal-kg.git
cd personal-kg
pnpm install
```

### 2.â€¯Configure Environment
Create `.env` in project root:
```bash
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASS=password
QDRANT_URL=http://localhost:6333
OPENAI_API_KEY=           # optional if using remote model
NOTES_DIR=./private/notes
```

### 3.â€¯Start Databases
```bash
docker compose -f docker/docker-compose.yml up -d
```

### 4.â€¯Develop
```bash
# run everything (frontend + backend)
pnpm turbo dev
```

Individual scopes:
```bash
# backend only
pnpm turbo dev --filter=server

# frontend only
pnpm turbo dev --filter=web
```

---

## ğŸ§  Ingestion Flow

1. Add Markdown notes under `private/notes/`  
2. Run indexer script (coming soon) to parse, chunk, and embed  
3. View relationships in Neo4j Browser  
4. Query via the chat UI on `localhost:3000`

All personal data under `/private` is `.gitignored`  
â€” it stays **local and versioned privately**.

---

## ğŸ³ Docker Services

| Service |â€¯Portâ€¯|â€¯Purpose |
|----------|------|---------|
| **neo4j** |â€¯7474 /â€¯7687 | Knowledge graph |
| **qdrant** |â€¯6333 | Vectorâ€¯memory |
| **server** |â€¯8000 | NestJSâ€¯API |
| **web** |â€¯3000 | Next.jsâ€¯UI |

---

## ğŸ§¾ Commands

| Task | Command |
|------|----------|
| Dev all | `pnpm turbo dev` |
| Build all | `pnpm turbo build` |
| Lint / format | `pnpm turbo lint` |
| Graph DB start | `docker compose up neo4j` |
| Vector DB start | `docker compose up qdrant` |

---

## ğŸ§­ Roadmap

- [ ] Markdown â†’â€¯NodeRAG entityâ€¯ingestion  
- [ ] Vectorâ€¯+â€¯Graphâ€¯hybridâ€¯retrieval  
- [ ] Agentic reflection with LlamaIndex  
- [ ] Local LLMâ€¯embedding viaâ€¯Ollama  
- [ ] Visualizationâ€¯/â€¯Searchâ€¯UI  

---

> â€œYour computer should remember you â€” not the other way around.â€